{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNKaJz5j_ylj"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "## Install and Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEfSbAA4QHas",
        "outputId": "4989ee91-c23e-4492-cb98-1cc90e5e463d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NmMdkZO8R6q",
        "outputId": "f88fc91c-476a-4dc1-aaa2-f8e0b38fe89f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.8)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.62.3)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.10.0.2)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.8 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.24.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.5.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.8->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.8->boto3->pytorch-pretrained-bert) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.8->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ok002ceNB8E7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oYsV4H8fCpZ-",
        "outputId": "43e07109-a9af-4da9-8818-88a85b18f562"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "fNetEz1xLsuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR7zXtM2j_XV"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv(\"/content/understatement_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it8ztkYCpoHs"
      },
      "source": [
        "this dataset consist of semeval training and test data + sem22 training data with data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "xfOe7C19kgTJ",
        "outputId": "582078cc-147d-4d2c-e4ee-dd1bea82e4c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-46efd64b-5d3c-46c1-9410-38aa4969f77c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>understatement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@ jimrossignol i will choose to interpret desc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>@ jimrossignol i choose to simply interpret it...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>@ jimrossignol i choose to interpret it today ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>i suppose even though, we actually did not sig...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>i suppose... though, we still did never sign o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>and i suppose though, though we did sign only ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>he started watching this house of cards, 4 epi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>started watching real house tricks of card car...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>you started watching house of wild cards, anot...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>drummer billy graham gunn sorta relevant for l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>actors billy gunn and sorta became relevant fo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>champion billy willie gunn won sorta relevant ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>okay alright but nothin like the say so song a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>yeah okay but like the guys say so song sure a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>okay anyway but like the girls say goodbye so ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>some lucky results for 2nd division placed sid...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>although lucky for its 2nd highest placed bren...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>lucky for the 2nd placed brentford that there'...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>there now is not enough of people here # the i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>sadly there apparently is not enough people li...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>there is still not quite enough people sitting...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>@ o c _ mike j _ mcburney will suspect there ’...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>@ c _ j _ john mcburney ′ suspect there ’ ″ s ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>@ c _ j _ m mcburney suspect — there ’ ‘ s sti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>could i get heard at it somebody might be snow...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>something i briefly heard above it that might ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>did i get heard like it might be cold snowing?...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>breaking my already strict record buying hiatu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>breaking my strict schedule buying time hiatus...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>breaking my strict schedule buying hiatus prom...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46efd64b-5d3c-46c1-9410-38aa4969f77c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46efd64b-5d3c-46c1-9410-38aa4969f77c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46efd64b-5d3c-46c1-9410-38aa4969f77c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Unnamed: 0  ... understatement\n",
              "0            0  ...              1\n",
              "1            1  ...              1\n",
              "2            2  ...              1\n",
              "3            3  ...              1\n",
              "4            4  ...              1\n",
              "5            5  ...              1\n",
              "6            6  ...              1\n",
              "7            7  ...              1\n",
              "8            8  ...              1\n",
              "9            9  ...              1\n",
              "10          10  ...              1\n",
              "11          11  ...              1\n",
              "12          12  ...              1\n",
              "13          13  ...              1\n",
              "14          14  ...              1\n",
              "15          15  ...              1\n",
              "16          16  ...              1\n",
              "17          17  ...              1\n",
              "18          18  ...              1\n",
              "19          19  ...              1\n",
              "20          20  ...              1\n",
              "21          21  ...              1\n",
              "22          22  ...              1\n",
              "23          23  ...              1\n",
              "24          24  ...              1\n",
              "25          25  ...              1\n",
              "26          26  ...              1\n",
              "27          27  ...              1\n",
              "28          28  ...              1\n",
              "29          29  ...              1\n",
              "\n",
              "[30 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df2.drop([\"Unnamed: 0\"],axis=1)"
      ],
      "metadata": {
        "id": "WVLFfTfAL5gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAdVCC5Ykk4d"
      },
      "outputs": [],
      "source": [
        "df2 = df2[[\"tweet\",\"understatement\"]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df30 = pd.read_csv(\"train.En (1).csv\")"
      ],
      "metadata": {
        "id": "VNJnV3dVLFzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df30_rhetorical_question= df30[[\"tweet\",\"understatement\"]]\n",
        "df30_rhetorical_question = df30_rhetorical_question[0:867]"
      ],
      "metadata": {
        "id": "8t721KVSK_ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aIMfWncELXXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_rhetorical_question=df2.append(df30_rhetorical_question)\n",
        "df_rhetorical_question =df_rhetorical_question.drop_duplicates(subset=['tweet'])\n",
        "df_rhetorical_question = df_rhetorical_question.astype({\"understatement\":int})"
      ],
      "metadata": {
        "id": "kDox4JLMLTAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_rhetorical_question"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lPDeSgfTLoA7",
        "outputId": "e7eb2bf8-1dc4-4de3-e1e2-679812bd40bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1a328e4a-5d60-438a-a494-a73a91f5780d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>understatement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@ jimrossignol i will choose to interpret desc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@ jimrossignol i choose to simply interpret it...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@ jimrossignol i choose to interpret it today ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i suppose even though, we actually did not sig...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i suppose... though, we still did never sign o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>yo @claires do yall do hysterectomies?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863</th>\n",
              "      <td>@JacobWohlReport Do I need to aquire a wife be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>I get a lot of boy who cried wolf vibes from t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>Update: holding hands with your mom and walkin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>I might be rubbish at driving, and have a less...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>897 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a328e4a-5d60-438a-a494-a73a91f5780d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a328e4a-5d60-438a-a494-a73a91f5780d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a328e4a-5d60-438a-a494-a73a91f5780d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 tweet  understatement\n",
              "0    @ jimrossignol i will choose to interpret desc...               1\n",
              "1    @ jimrossignol i choose to simply interpret it...               1\n",
              "2    @ jimrossignol i choose to interpret it today ...               1\n",
              "3    i suppose even though, we actually did not sig...               1\n",
              "4    i suppose... though, we still did never sign o...               1\n",
              "..                                                 ...             ...\n",
              "862             yo @claires do yall do hysterectomies?               0\n",
              "863  @JacobWohlReport Do I need to aquire a wife be...               0\n",
              "864  I get a lot of boy who cried wolf vibes from t...               0\n",
              "865  Update: holding hands with your mom and walkin...               0\n",
              "866  I might be rubbish at driving, and have a less...               0\n",
              "\n",
              "[897 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_rhetorical_question"
      ],
      "metadata": {
        "id": "YJWmwsTDMeSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "AQfTaYDo42zu",
        "outputId": "8c90c0bd-91f2-41f3-ae8a-cd9ea7de36b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cceacaff-12ec-4e68-a4f2-7fb23ee531dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>understatement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>787</th>\n",
              "      <td>@MatthewStadlen @sajidjavid Thank you so much ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>wow. i left on time today and the airport conn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Not at all concerning that a man's just been r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>Searching for Pokemon later because I hate mys...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>but clinton's emails!\\noh.\\nemm.\\nfucking.\\nge...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>606</th>\n",
              "      <td>my car is acting up AGAIN for like the 3rd yea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>I'm literally out here trading eggs for potato...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841</th>\n",
              "      <td>Fav this and I won't send you a name of a rand...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>616</th>\n",
              "      <td>Don’t you just love it when they dig up your r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>thinking about quitting the path im on to beco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cceacaff-12ec-4e68-a4f2-7fb23ee531dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cceacaff-12ec-4e68-a4f2-7fb23ee531dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cceacaff-12ec-4e68-a4f2-7fb23ee531dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 tweet  understatement\n",
              "787  @MatthewStadlen @sajidjavid Thank you so much ...               0\n",
              "216  wow. i left on time today and the airport conn...               0\n",
              "27   Not at all concerning that a man's just been r...               0\n",
              "629  Searching for Pokemon later because I hate mys...               0\n",
              "368  but clinton's emails!\\noh.\\nemm.\\nfucking.\\nge...               0\n",
              "606  my car is acting up AGAIN for like the 3rd yea...               0\n",
              "694  I'm literally out here trading eggs for potato...               0\n",
              "841  Fav this and I won't send you a name of a rand...               0\n",
              "616  Don’t you just love it when they dig up your r...               0\n",
              "110  thinking about quitting the path im on to beco...               0"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3DjEe9eeCm_",
        "outputId": "dc2d1181-f239-49f9-b2ed-ea8c4b9a65a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    857\n",
              "1     40\n",
              "Name: understatement, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ],
      "source": [
        "df[\"understatement\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"understatement_all_data.csv\")"
      ],
      "metadata": {
        "id": "7qZkevCJRT0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJMHkIvWpoH5"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clkFG-g1LS_e",
        "outputId": "8e2761d4-f107-460b-bc8a-e6e07b218a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import nltk.corpus\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "\n",
        "b = list(df[\"tweet\"])\n",
        "corpus = []\n",
        "for i in range(len(b)):\n",
        "    review =re.sub(r'http\\S+', ' ', str(b[i]))\n",
        "    review = re.sub(\"\\d*\\.\\d+\",\"\",review) # remove float \n",
        "    review =re.sub(r'@\\S+', ' ', review)\n",
        "    \n",
        "    TAG_RE = re.compile(r'<[^>]+>')\n",
        "    review = TAG_RE.sub('', review)\n",
        "\n",
        "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
        "    \n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = ' '.join(review)\n",
        "\n",
        "    \n",
        "\n",
        "    corpus.append(review)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APY0U2xiMLuS"
      },
      "outputs": [],
      "source": [
        "df = df.assign(clean_headlines = corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "DlY6XbOQMqTT",
        "outputId": "c51bc6dd-084f-41a3-9332-4c5449515dbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b888da37-ba7b-4e48-bf9b-a03a881caec0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>understatement</th>\n",
              "      <th>clean_headlines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@ jimrossignol i will choose to interpret desc...</td>\n",
              "      <td>1</td>\n",
              "      <td>@ jimrossignol i will choose to interpret desc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@ jimrossignol i choose to simply interpret it...</td>\n",
              "      <td>1</td>\n",
              "      <td>@ jimrossignol i choose to simply interpret it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@ jimrossignol i choose to interpret it today ...</td>\n",
              "      <td>1</td>\n",
              "      <td>@ jimrossignol i choose to interpret it today ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i suppose even though, we actually did not sig...</td>\n",
              "      <td>1</td>\n",
              "      <td>i suppose even though, we actually did not sig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i suppose... though, we still did never sign o...</td>\n",
              "      <td>1</td>\n",
              "      <td>i suppose... though, we still did never sign o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>yo @claires do yall do hysterectomies?</td>\n",
              "      <td>0</td>\n",
              "      <td>yo do yall do hysterectomies?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863</th>\n",
              "      <td>@JacobWohlReport Do I need to aquire a wife be...</td>\n",
              "      <td>0</td>\n",
              "      <td>do i need to aquire a wife before this happens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>I get a lot of boy who cried wolf vibes from t...</td>\n",
              "      <td>0</td>\n",
              "      <td>i get a lot of boy who cried wolf vibes from t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>Update: holding hands with your mom and walkin...</td>\n",
              "      <td>0</td>\n",
              "      <td>update: holding hands with your mom and walkin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>I might be rubbish at driving, and have a less...</td>\n",
              "      <td>0</td>\n",
              "      <td>i might be rubbish at driving, and have a less...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>897 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b888da37-ba7b-4e48-bf9b-a03a881caec0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b888da37-ba7b-4e48-bf9b-a03a881caec0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b888da37-ba7b-4e48-bf9b-a03a881caec0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 tweet  ...                                    clean_headlines\n",
              "0    @ jimrossignol i will choose to interpret desc...  ...  @ jimrossignol i will choose to interpret desc...\n",
              "1    @ jimrossignol i choose to simply interpret it...  ...  @ jimrossignol i choose to simply interpret it...\n",
              "2    @ jimrossignol i choose to interpret it today ...  ...  @ jimrossignol i choose to interpret it today ...\n",
              "3    i suppose even though, we actually did not sig...  ...  i suppose even though, we actually did not sig...\n",
              "4    i suppose... though, we still did never sign o...  ...  i suppose... though, we still did never sign o...\n",
              "..                                                 ...  ...                                                ...\n",
              "862             yo @claires do yall do hysterectomies?  ...                      yo do yall do hysterectomies?\n",
              "863  @JacobWohlReport Do I need to aquire a wife be...  ...  do i need to aquire a wife before this happens...\n",
              "864  I get a lot of boy who cried wolf vibes from t...  ...  i get a lot of boy who cried wolf vibes from t...\n",
              "865  Update: holding hands with your mom and walkin...  ...  update: holding hands with your mom and walkin...\n",
              "866  I might be rubbish at driving, and have a less...  ...  i might be rubbish at driving, and have a less...\n",
              "\n",
              "[897 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XodhrvVDpoH6"
      },
      "source": [
        "# Add special tokens at the beginning and end of each sentence for BERT to work properly "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "outputs": [],
      "source": [
        "# Create sentence and label lists\n",
        "sentences = df.clean_headlines.values\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = df.understatement.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "## Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTREubVNFiz4"
      },
      "source": [
        "Next, import the BERT tokenizer, used to convert our text into tokens that correspond to BERT's vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PniouibtahT",
        "outputId": "665adaba-df97-48fc-fd6c-765f24f39293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.21.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (0.1.96)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.62.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (0.0.47)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.21.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.8 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (1.24.8)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (0.5.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.8->boto3->pytorch-transformers) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.8->boto3->pytorch-transformers) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.8->boto3->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-transformers\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODCKPuvMtVwF"
      },
      "outputs": [],
      "source": [
        "from pytorch_transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
        "from pytorch_transformers import AdamW\n",
        "\n",
        "from tqdm import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z474sSC6oe7A",
        "outputId": "2c9d507b-aecc-474d-acc7-a8d50e50d21f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenize the first sentence:\n",
            "['[CLS]', '@', 'jim', '##ross', '##ign', '##ol', 'i', 'will', 'choose', 'to', 'interpret', 'describing', 'it', 'as', '\"', 'x', '##d', '\"', ':', 'the', 'universal', 'slang', 'em', '##otic', '##on', 'for', 'laughing', 'out', 'at', 'those', 'really', 'poor', ',', 'poor', 'folks', 'in', 'u', '##bis', '##oft', \"'\", 's', 'marketing', 'department', 'who', 'already', 'have', 'tended', 'to', 'deal', 'exclusively', 'with', 'that', 'branding', 'issue', 'until', 'the', 'servers', 'have', 'quietly', 'shut', 'down', '8', 'months', 'after', 'launch', '.', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print (\"Tokenize the first sentence:\")\n",
        "print (tokenized_texts[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87_kXUeT2-br"
      },
      "source": [
        "BERT requires specifically formatted inputs. For each tokenized input sentence, we need to create:\n",
        "\n",
        "- **input ids**: a sequence of integers identifying each input token to its index number in the BERT tokenizer vocabulary\n",
        "- **segment mask**: (optional) a sequence of 1s and 0s used to identify whether the input is one sentence or two sentences long. For one sentence inputs, this is simply a sequence of 0s. For two sentence inputs, there is a 0 for each token of the first sentence, followed by a 1 for each token of the second sentence\n",
        "- **attention mask**: (optional) a sequence of 1s and 0s, with 1s for all input tokens and 0s for all padding tokens (we'll detail this in the next paragraph)\n",
        "- **labels**: a single value of 1 or 0. In our task 1 means \"grammatical\" and 0 means \"ungrammatical\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xytsw1oIfnX0"
      },
      "source": [
        "Although we can have variable length input sentences, BERT does requires our input arrays to be the same size. We address this by first choosing a maximum sentence length, and then padding and truncating our inputs until every input sequence is of the same length. \n",
        "\n",
        "To \"pad\" our inputs in this context means that if a sentence is shorter than the maximum sentence length, we simply add 0s to the end of the sequence until it is the maximum sentence length. \n",
        "\n",
        "If a sentence is longer than the maximum sentence length, then we simply truncate the end of the sequence, discarding anything that does not fit into our maximum sentence length.\n",
        "\n",
        "We pad and truncate our sequences so that they all become of length MAX_LEN (\"post\" indicates that we want to pad and truncate at the end of the sequence, as opposed to the beginning) `pad_sequences` is a utility function that we're borrowing from Keras. It simply handles the truncating and padding of Python lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp9BPRd1tMIo"
      },
      "outputs": [],
      "source": [
        "# Set the maximum sequence length \n",
        "MAX_LEN = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZeXeNXgo0iQ"
      },
      "outputs": [],
      "source": [
        "# Pad our input tokens\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFhowDMohU4H"
      },
      "outputs": [],
      "source": [
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDs-MYtYH8sL"
      },
      "outputs": [],
      "source": [
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhGulL1pExCT"
      },
      "source": [
        "# Create the attention masks "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDoC24LeEv3N"
      },
      "outputs": [],
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3pmYGGRpoH-"
      },
      "source": [
        "# Split our data into train and validation sets for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFbE-UHvsb7-"
      },
      "outputs": [],
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALgrakUNpoH_"
      },
      "source": [
        "# Convert all of our data into torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw5K2A5Ko1RF"
      },
      "outputs": [],
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "outputs": [],
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNl8khAhPYju"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwQ7JcuJQZ0o"
      },
      "source": [
        "Now that our input data is properly formatted, it's time to fine tune the BERT model. \n",
        "\n",
        "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
        "\n",
        "We'll load [BertForSequenceClassification](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py#L1129). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n",
        "\n",
        "\n",
        "### The Fine-Tuning Process\n",
        "\n",
        "Because the pre-trained BERT layers already encode a lot of information about the language, training the classifier is relatively inexpensive. Rather than training every layer in a large model from scratch, it's as if we have already trained the bottom layers 95% of where they need to be, and only really need to train the top layer, with a bit of tweaking going on in the lower levels to accomodate our task.\n",
        "\n",
        "Sometimes practicioners will opt to \"freeze\" certain layers when fine-tuning, or to apply different learning rates, apply diminishing learning rates, etc. all in an effort to preserve the good quality weights in the network and speed up training (often considerably). In fact, recent research on BERT specifically has demonstrated that freezing the majority of the weights results in only minimal accuracy declines, but there are exceptions and broader rules of transfer learning that should also be considered. For example, if your task and fine-tuning dataset is very different from the dataset used to train the transfer learning model, freezing the weights may not be a good idea. We'll cover the broader scope of transfer learning in NLP in a future post.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnQW9E-bBCRt"
      },
      "source": [
        "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFsCTp_mporB",
        "outputId": "d8b49bc3-c2a5-4653-a508-39f3ce8fa67c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ],
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuning,recommended the following hyperparameter ranges:\n",
        "- Batch size: 16, 32\n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "- Number of epochs: 2, 3, 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxSMw0FrptiL"
      },
      "outputs": [],
      "source": [
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLs72DuMODJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de07066d-12b1-45e7-fb2c-508851bc9547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ],
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=2e-5,\n",
        "                     warmup=.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXZhFb4LnV5"
      },
      "source": [
        "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. At each pass we need to:\n",
        "\n",
        "Training loop:\n",
        "- Tell the model to compute gradients by setting the model in train mode\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Clear out the gradients calculated in the previous pass. In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "Evalution loop:\n",
        "- Tell the model not to compute gradients by setting th emodel in evaluation mode\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBzobghA22uD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd785203-31d5-493f-fdff-8638bc16b43a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.2749115222205336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\rEpoch:  33%|███▎      | 1/3 [00:20<00:40, 20.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9767628205128206\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        88\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.98        90\n",
            "   macro avg       0.49      0.50      0.49        90\n",
            "weighted avg       0.96      0.98      0.97        90\n",
            "\n",
            "Train loss: 0.1631396235898137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\rEpoch:  67%|██████▋   | 2/3 [00:40<00:20, 20.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9767628205128206\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        88\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.98        90\n",
            "   macro avg       0.49      0.50      0.49        90\n",
            "weighted avg       0.96      0.98      0.97        90\n",
            "\n",
            "Train loss: 0.07697157687149368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 3/3 [01:00<00:00, 20.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9767628205128206\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        88\n",
            "           1       0.50      1.00      0.67         2\n",
            "\n",
            "    accuracy                           0.98        90\n",
            "   macro avg       0.75      0.99      0.83        90\n",
            "weighted avg       0.99      0.98      0.98        90\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "  predictions , true_labels = [], []\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()    \n",
        "    flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "  \n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "  print(classification_report(flat_true_labels, flat_predictions)) #print classification report after every report \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyRa-5CcHv_g"
      },
      "source": [
        "## Training Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "Let's take a look at our training loss over all batches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "97343a18-2592-46b1-8c74-de8e909c9410"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB7_uU-6poII"
      },
      "source": [
        "# Prediction on test data (unseen and unlabeled data )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKhHhoz4w_Y8"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv(\"/content/taskB.En.input.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3BILwAkx1GQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "6478df52-0bdd-47e0-9322-c27a134edca6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-90f2010f-b155-49b0-ad68-dda4832953ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saw a video of someone getting a hug. would LO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"This Christmas I hope you all either get vacc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's the alamo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I constantly have loads of the new symptoms bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>Tempting to renew my membership and vote again...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>This week has felt like the longest in history...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Of course it’s raining when I’m due to go out ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>Weigh up a lie before you tell it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>Upand dressed at a reasonable time once again ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90f2010f-b155-49b0-ad68-dda4832953ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90f2010f-b155-49b0-ad68-dda4832953ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90f2010f-b155-49b0-ad68-dda4832953ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text\n",
              "0     saw a video of someone getting a hug. would LO...\n",
              "1     \"This Christmas I hope you all either get vacc...\n",
              "2                                        It's the alamo\n",
              "3     Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...\n",
              "4     I constantly have loads of the new symptoms bu...\n",
              "...                                                 ...\n",
              "1395  Tempting to renew my membership and vote again...\n",
              "1396  This week has felt like the longest in history...\n",
              "1397  Of course it’s raining when I’m due to go out ...\n",
              "1398                 Weigh up a lie before you tell it.\n",
              "1399  Upand dressed at a reasonable time once again ...\n",
              "\n",
              "[1400 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-10XM0r8xqUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9039c9-016e-400c-d68a-7991686717d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "ps = PorterStemmer()\n",
        "\n",
        "\n",
        "b = list(test_data[\"text\"])\n",
        "\n",
        "\n",
        "wordnet=WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "import nltk.corpus\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "import string\n",
        "exclude = set(string.punctuation)\n",
        "corpus = []\n",
        "for i in range(len(b)):\n",
        "    review =re.sub(r'http\\S+', ' ', str(b[i]))\n",
        "    review = re.sub(\"\\d*\\.\\d+\",\"\",review)\n",
        "    review =re.sub(r'@\\S+', ' ', review)\n",
        "    \n",
        "    \n",
        "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
        "    \n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = ' '.join(review)\n",
        "\n",
        "    \n",
        "\n",
        "    corpus.append(review)\n",
        "test_data = test_data.assign(clean_text = corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQvSSG0SpoIJ"
      },
      "source": [
        "let's assume that label of all tweets is zero \n",
        "it does not effect on prediction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swYraRFDyRO0"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.assign(random_label=[0 for i in range(len(test_data[\"clean_text\"]))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbDvHbcfyhfq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "0083e2ff-7ee7-41c8-9e8f-1978e8a7e729"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8cea3678-2864-4512-a2e3-b59e85bf6fd5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>random_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saw a video of someone getting a hug. would LO...</td>\n",
              "      <td>saw a video of someone getting a hug. would lo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"This Christmas I hope you all either get vacc...</td>\n",
              "      <td>\"this christmas i hope you all either get vacc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's the alamo</td>\n",
              "      <td>it's the alamo</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...</td>\n",
              "      <td>wind 5 mph e. barometer hpa, pressure trend. t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I constantly have loads of the new symptoms bu...</td>\n",
              "      <td>i constantly have loads of the new symptoms bu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>Tempting to renew my membership and vote again...</td>\n",
              "      <td>tempting to renew my membership and vote again...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>This week has felt like the longest in history...</td>\n",
              "      <td>this week has felt like the longest in history...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Of course it’s raining when I’m due to go out ...</td>\n",
              "      <td>of course it’s raining when i’m due to go out ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>Weigh up a lie before you tell it.</td>\n",
              "      <td>weigh up a lie before you tell it.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>Upand dressed at a reasonable time once again ...</td>\n",
              "      <td>upand dressed at a reasonable time once again ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cea3678-2864-4512-a2e3-b59e85bf6fd5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8cea3678-2864-4512-a2e3-b59e85bf6fd5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8cea3678-2864-4512-a2e3-b59e85bf6fd5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text  ... random_label\n",
              "0     saw a video of someone getting a hug. would LO...  ...            0\n",
              "1     \"This Christmas I hope you all either get vacc...  ...            0\n",
              "2                                        It's the alamo  ...            0\n",
              "3     Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...  ...            0\n",
              "4     I constantly have loads of the new symptoms bu...  ...            0\n",
              "...                                                 ...  ...          ...\n",
              "1395  Tempting to renew my membership and vote again...  ...            0\n",
              "1396  This week has felt like the longest in history...  ...            0\n",
              "1397  Of course it’s raining when I’m due to go out ...  ...            0\n",
              "1398                 Weigh up a lie before you tell it.  ...            0\n",
              "1399  Upand dressed at a reasonable time once again ...  ...            0\n",
              "\n",
              "[1400 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 233
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAg6Z5LmyKDL"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = test_data.clean_text.values\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = test_data.random_label.values\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "\n",
        "MAX_LEN = 128\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "  \n",
        "batch_size = 32  \n",
        "\n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6plBf36x-kW"
      },
      "outputs": [],
      "source": [
        "# Prediction on test set\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIxxG7ciyrar"
      },
      "outputs": [],
      "source": [
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxYGa6Bfy7Kn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feeec6c3-d5c0-402f-d9ce-9882e16a897a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ],
      "source": [
        "flat_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89OleVEzy93Z"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.assign(predicted_label=list(flat_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5-bBkLlzS2k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "b15ef7f9-714b-4ac6-c4e1-119faa9557bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-614e3163-a38d-498c-87a2-6343bcf551c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>random_label</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saw a video of someone getting a hug. would LO...</td>\n",
              "      <td>saw a video of someone getting a hug. would lo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"This Christmas I hope you all either get vacc...</td>\n",
              "      <td>\"this christmas i hope you all either get vacc...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's the alamo</td>\n",
              "      <td>it's the alamo</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...</td>\n",
              "      <td>wind 5 mph e. barometer hpa, pressure trend. t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I constantly have loads of the new symptoms bu...</td>\n",
              "      <td>i constantly have loads of the new symptoms bu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>Tempting to renew my membership and vote again...</td>\n",
              "      <td>tempting to renew my membership and vote again...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>This week has felt like the longest in history...</td>\n",
              "      <td>this week has felt like the longest in history...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Of course it’s raining when I’m due to go out ...</td>\n",
              "      <td>of course it’s raining when i’m due to go out ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>Weigh up a lie before you tell it.</td>\n",
              "      <td>weigh up a lie before you tell it.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>Upand dressed at a reasonable time once again ...</td>\n",
              "      <td>upand dressed at a reasonable time once again ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-614e3163-a38d-498c-87a2-6343bcf551c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-614e3163-a38d-498c-87a2-6343bcf551c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-614e3163-a38d-498c-87a2-6343bcf551c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text  ... predicted_label\n",
              "0     saw a video of someone getting a hug. would LO...  ...               0\n",
              "1     \"This Christmas I hope you all either get vacc...  ...               0\n",
              "2                                        It's the alamo  ...               0\n",
              "3     Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...  ...               0\n",
              "4     I constantly have loads of the new symptoms bu...  ...               0\n",
              "...                                                 ...  ...             ...\n",
              "1395  Tempting to renew my membership and vote again...  ...               0\n",
              "1396  This week has felt like the longest in history...  ...               0\n",
              "1397  Of course it’s raining when I’m due to go out ...  ...               0\n",
              "1398                 Weigh up a lie before you tell it.  ...               0\n",
              "1399  Upand dressed at a reasonable time once again ...  ...               0\n",
              "\n",
              "[1400 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd8-Bj2TzXYS"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.drop([\"text\",\"clean_text\",\"random_label\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ggjw4cdszpYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed793627-50ea-4435-ee4d-a061328c6b01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1375\n",
              "1      25\n",
              "Name: predicted_label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ],
      "source": [
        "test_data[\"predicted_label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MKC96QT0gD6"
      },
      "outputs": [],
      "source": [
        "test_data.to_csv(\"understatement_test_pred.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "BERT_Fine_Tuning_Sentence_Classification_understatement.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}