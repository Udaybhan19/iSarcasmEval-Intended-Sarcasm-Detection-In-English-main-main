{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNKaJz5j_ylj"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "## Install and Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEfSbAA4QHas",
        "outputId": "e78e01e2-a33c-4e1d-db4c-8b9e0e603888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NmMdkZO8R6q",
        "outputId": "2bbd41d9-6836-47d6-f385-0e8a26a6582f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.10.0.2)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.8 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.24.8)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.5.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.8->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.8->boto3->pytorch-pretrained-bert) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.8->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ok002ceNB8E7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oYsV4H8fCpZ-",
        "outputId": "6ab3e4e1-d136-40a9-944d-d1ec2db66148"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "fNetEz1xLsuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR7zXtM2j_XV"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv(\"/content/overstatement_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it8ztkYCpoHs"
      },
      "source": [
        "this dataset consist of semeval training and test data + sem22 training data with data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xfOe7C19kgTJ",
        "outputId": "89474a4f-f6e2-4668-ae8b-fabd03010f67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-57ea9958-9152-429c-a935-5aa658efd4e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>overstatement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>over 90 % of adulthood ale is consumed just re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>another 90 % amount of adulthood intake is jus...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>90 % percent of adulthood consumers is just en...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>he heard a rumor happen that a baja vista blas...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>heard a common rumor that baja energy blast is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>115</td>\n",
              "      <td>if you just don't feel like lemonade pie you'm...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>116</td>\n",
              "      <td>maybe if you just don't like lemonade soup you...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>117</td>\n",
              "      <td>i ’ ″ m already dying</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>118</td>\n",
              "      <td>when i really ’ m dying</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>119</td>\n",
              "      <td>i ’... m not dying</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57ea9958-9152-429c-a935-5aa658efd4e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57ea9958-9152-429c-a935-5aa658efd4e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57ea9958-9152-429c-a935-5aa658efd4e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Unnamed: 0  ... overstatement\n",
              "0             0  ...             1\n",
              "1             1  ...             1\n",
              "2             2  ...             1\n",
              "3             3  ...             1\n",
              "4             4  ...             1\n",
              "..          ...  ...           ...\n",
              "115         115  ...             1\n",
              "116         116  ...             1\n",
              "117         117  ...             1\n",
              "118         118  ...             1\n",
              "119         119  ...             1\n",
              "\n",
              "[120 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df2.drop([\"Unnamed: 0\"],axis=1)"
      ],
      "metadata": {
        "id": "WVLFfTfAL5gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAdVCC5Ykk4d"
      },
      "outputs": [],
      "source": [
        "df2 = df2[[\"tweet\",\"overstatement\"]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df30 = pd.read_csv(\"train.En (1).csv\")"
      ],
      "metadata": {
        "id": "VNJnV3dVLFzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df30_overstatement= df30[[\"tweet\",\"overstatement\"]]\n",
        "df30_overstatement = df30_rhetorical_question[0:867]"
      ],
      "metadata": {
        "id": "8t721KVSK_ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aIMfWncELXXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_overstatement_question=df2.append(df30_x)\n",
        "df_overstatement =df_overstatement.drop_duplicates(subset=['tweet'])\n",
        "df_overstatement = df_roverstatement.astype({\"overstatement\":int})"
      ],
      "metadata": {
        "id": "kDox4JLMLTAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_overstatement"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lPDeSgfTLoA7",
        "outputId": "b6272895-f962-45ca-89a7-9e2715d9ff64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-affd3344-55bc-4cb9-a0dd-e8c400eaf13b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>overstatement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>over 90 % of adulthood ale is consumed just re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>another 90 % amount of adulthood intake is jus...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90 % percent of adulthood consumers is just en...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>he heard a rumor happen that a baja vista blas...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>heard a common rumor that baja energy blast is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>yo @claires do yall do hysterectomies?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863</th>\n",
              "      <td>@JacobWohlReport Do I need to aquire a wife be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>I get a lot of boy who cried wolf vibes from t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>Update: holding hands with your mom and walkin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>I might be rubbish at driving, and have a less...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>987 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-affd3344-55bc-4cb9-a0dd-e8c400eaf13b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-affd3344-55bc-4cb9-a0dd-e8c400eaf13b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-affd3344-55bc-4cb9-a0dd-e8c400eaf13b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 tweet  overstatement\n",
              "0    over 90 % of adulthood ale is consumed just re...              1\n",
              "1    another 90 % amount of adulthood intake is jus...              1\n",
              "2    90 % percent of adulthood consumers is just en...              1\n",
              "3    he heard a rumor happen that a baja vista blas...              1\n",
              "4    heard a common rumor that baja energy blast is...              1\n",
              "..                                                 ...            ...\n",
              "862             yo @claires do yall do hysterectomies?              0\n",
              "863  @JacobWohlReport Do I need to aquire a wife be...              0\n",
              "864  I get a lot of boy who cried wolf vibes from t...              0\n",
              "865  Update: holding hands with your mom and walkin...              0\n",
              "866  I might be rubbish at driving, and have a less...              0\n",
              "\n",
              "[987 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_overstatement"
      ],
      "metadata": {
        "id": "YJWmwsTDMeSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "AQfTaYDo42zu",
        "outputId": "952fc415-5214-451d-a01e-000abb222df8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-da6c57e4-9e42-4d8f-aa1e-a2e9e9e48567\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>overstatement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>what a great day to be stuck inside 🙃</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>matt hancock johnson is still a vermont top sh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>i went outside today and suddenly my depressio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Been trying to get my boyfriends attention. Le...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>hello to all and three of them my loyal follow...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>it’s always the girls I don’t even know that w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>What kind of sins have y’all been committing f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>the only ppl who should be worried about Biden...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>Dear @krispykremeUK,\\n\\nI see your enticing #T...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>it's all about women in stem struggles. what a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da6c57e4-9e42-4d8f-aa1e-a2e9e9e48567')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da6c57e4-9e42-4d8f-aa1e-a2e9e9e48567 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da6c57e4-9e42-4d8f-aa1e-a2e9e9e48567');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 tweet  overstatement\n",
              "490              what a great day to be stuck inside 🙃              0\n",
              "57   matt hancock johnson is still a vermont top sh...              1\n",
              "288  i went outside today and suddenly my depressio...              0\n",
              "97   Been trying to get my boyfriends attention. Le...              0\n",
              "30   hello to all and three of them my loyal follow...              1\n",
              "127  it’s always the girls I don’t even know that w...              0\n",
              "259  What kind of sins have y’all been committing f...              0\n",
              "423  the only ppl who should be worried about Biden...              0\n",
              "565  Dear @krispykremeUK,\\n\\nI see your enticing #T...              0\n",
              "721  it's all about women in stem struggles. what a...              0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3DjEe9eeCm_",
        "outputId": "660235cd-2f9a-4859-ec91-f5e2944b913e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    827\n",
              "1    160\n",
              "Name: overstatement, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df[\"overstatement\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"overstatement_all_data.csv\")"
      ],
      "metadata": {
        "id": "7qZkevCJRT0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJMHkIvWpoH5"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clkFG-g1LS_e",
        "outputId": "abef8e0b-3462-4221-8533-c58b960a797a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import nltk.corpus\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "\n",
        "b = list(df[\"tweet\"])\n",
        "corpus = []\n",
        "for i in range(len(b)):\n",
        "    review =re.sub(r'http\\S+', ' ', str(b[i]))\n",
        "    review = re.sub(\"\\d*\\.\\d+\",\"\",review) # remove float \n",
        "    review =re.sub(r'@\\S+', ' ', review)\n",
        "    \n",
        "    TAG_RE = re.compile(r'<[^>]+>')\n",
        "    review = TAG_RE.sub('', review)\n",
        "\n",
        "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
        "    \n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = ' '.join(review)\n",
        "\n",
        "    \n",
        "\n",
        "    corpus.append(review)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APY0U2xiMLuS"
      },
      "outputs": [],
      "source": [
        "df = df.assign(clean_headlines = corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "DlY6XbOQMqTT",
        "outputId": "4d8e1b19-32cf-4ecb-a6b0-2963b15952b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-704b4ede-0513-4130-a9a7-70b9a637d605\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>overstatement</th>\n",
              "      <th>clean_headlines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>over 90 % of adulthood ale is consumed just re...</td>\n",
              "      <td>1</td>\n",
              "      <td>over 90 % of adulthood ale is consumed just re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>another 90 % amount of adulthood intake is jus...</td>\n",
              "      <td>1</td>\n",
              "      <td>another 90 % amount of adulthood intake is jus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90 % percent of adulthood consumers is just en...</td>\n",
              "      <td>1</td>\n",
              "      <td>90 % percent of adulthood consumers is just en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>he heard a rumor happen that a baja vista blas...</td>\n",
              "      <td>1</td>\n",
              "      <td>he heard a rumor happen that a baja vista blas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>heard a common rumor that baja energy blast is...</td>\n",
              "      <td>1</td>\n",
              "      <td>heard a common rumor that baja energy blast is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>yo @claires do yall do hysterectomies?</td>\n",
              "      <td>0</td>\n",
              "      <td>yo do yall do hysterectomies?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863</th>\n",
              "      <td>@JacobWohlReport Do I need to aquire a wife be...</td>\n",
              "      <td>0</td>\n",
              "      <td>do i need to aquire a wife before this happens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>I get a lot of boy who cried wolf vibes from t...</td>\n",
              "      <td>0</td>\n",
              "      <td>i get a lot of boy who cried wolf vibes from t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>Update: holding hands with your mom and walkin...</td>\n",
              "      <td>0</td>\n",
              "      <td>update: holding hands with your mom and walkin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>I might be rubbish at driving, and have a less...</td>\n",
              "      <td>0</td>\n",
              "      <td>i might be rubbish at driving, and have a less...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>987 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-704b4ede-0513-4130-a9a7-70b9a637d605')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-704b4ede-0513-4130-a9a7-70b9a637d605 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-704b4ede-0513-4130-a9a7-70b9a637d605');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 tweet  ...                                    clean_headlines\n",
              "0    over 90 % of adulthood ale is consumed just re...  ...  over 90 % of adulthood ale is consumed just re...\n",
              "1    another 90 % amount of adulthood intake is jus...  ...  another 90 % amount of adulthood intake is jus...\n",
              "2    90 % percent of adulthood consumers is just en...  ...  90 % percent of adulthood consumers is just en...\n",
              "3    he heard a rumor happen that a baja vista blas...  ...  he heard a rumor happen that a baja vista blas...\n",
              "4    heard a common rumor that baja energy blast is...  ...  heard a common rumor that baja energy blast is...\n",
              "..                                                 ...  ...                                                ...\n",
              "862             yo @claires do yall do hysterectomies?  ...                      yo do yall do hysterectomies?\n",
              "863  @JacobWohlReport Do I need to aquire a wife be...  ...  do i need to aquire a wife before this happens...\n",
              "864  I get a lot of boy who cried wolf vibes from t...  ...  i get a lot of boy who cried wolf vibes from t...\n",
              "865  Update: holding hands with your mom and walkin...  ...  update: holding hands with your mom and walkin...\n",
              "866  I might be rubbish at driving, and have a less...  ...  i might be rubbish at driving, and have a less...\n",
              "\n",
              "[987 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XodhrvVDpoH6"
      },
      "source": [
        "# Add special tokens at the beginning and end of each sentence for BERT to work properly "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "outputs": [],
      "source": [
        "# Create sentence and label lists\n",
        "sentences = df.clean_headlines.values\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = df.overstatement.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "## Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTREubVNFiz4"
      },
      "source": [
        "Next, import the BERT tokenizer, used to convert our text into tokens that correspond to BERT's vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PniouibtahT",
        "outputId": "846e755f-7939-4aae-924a-3b847c6502fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 176 kB 14.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.62.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.21.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.21.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 51.3 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.8 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (1.24.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.8->boto3->pytorch-transformers) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.8->boto3->pytorch-transformers) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.8->boto3->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Installing collected packages: sentencepiece, sacremoses, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.47 sentencepiece-0.1.96\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 18.6 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 tokenizers-0.11.6 transformers-4.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-transformers\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODCKPuvMtVwF"
      },
      "outputs": [],
      "source": [
        "from pytorch_transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
        "from pytorch_transformers import AdamW\n",
        "\n",
        "from tqdm import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z474sSC6oe7A",
        "outputId": "46ee0cb8-8954-420e-e475-dcab99685691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 13598125.29B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenize the first sentence:\n",
            "['[CLS]', 'over', '90', '%', 'of', 'adulthood', 'ale', 'is', 'consumed', 'just', 'ref', '##ill', '##ing', 'in', 'your', 'own', 'brit', '##a', 'pitcher', '.', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print (\"Tokenize the first sentence:\")\n",
        "print (tokenized_texts[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87_kXUeT2-br"
      },
      "source": [
        "BERT requires specifically formatted inputs. For each tokenized input sentence, we need to create:\n",
        "\n",
        "- **input ids**: a sequence of integers identifying each input token to its index number in the BERT tokenizer vocabulary\n",
        "- **segment mask**: (optional) a sequence of 1s and 0s used to identify whether the input is one sentence or two sentences long. For one sentence inputs, this is simply a sequence of 0s. For two sentence inputs, there is a 0 for each token of the first sentence, followed by a 1 for each token of the second sentence\n",
        "- **attention mask**: (optional) a sequence of 1s and 0s, with 1s for all input tokens and 0s for all padding tokens (we'll detail this in the next paragraph)\n",
        "- **labels**: a single value of 1 or 0. In our task 1 means \"grammatical\" and 0 means \"ungrammatical\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xytsw1oIfnX0"
      },
      "source": [
        "Although we can have variable length input sentences, BERT does requires our input arrays to be the same size. We address this by first choosing a maximum sentence length, and then padding and truncating our inputs until every input sequence is of the same length. \n",
        "\n",
        "To \"pad\" our inputs in this context means that if a sentence is shorter than the maximum sentence length, we simply add 0s to the end of the sequence until it is the maximum sentence length. \n",
        "\n",
        "If a sentence is longer than the maximum sentence length, then we simply truncate the end of the sequence, discarding anything that does not fit into our maximum sentence length.\n",
        "\n",
        "We pad and truncate our sequences so that they all become of length MAX_LEN (\"post\" indicates that we want to pad and truncate at the end of the sequence, as opposed to the beginning) `pad_sequences` is a utility function that we're borrowing from Keras. It simply handles the truncating and padding of Python lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp9BPRd1tMIo"
      },
      "outputs": [],
      "source": [
        "# Set the maximum sequence length \n",
        "MAX_LEN = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZeXeNXgo0iQ"
      },
      "outputs": [],
      "source": [
        "# Pad our input tokens\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFhowDMohU4H"
      },
      "outputs": [],
      "source": [
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDs-MYtYH8sL"
      },
      "outputs": [],
      "source": [
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhGulL1pExCT"
      },
      "source": [
        "# Create the attention masks "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDoC24LeEv3N"
      },
      "outputs": [],
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3pmYGGRpoH-"
      },
      "source": [
        "# Split our data into train and validation sets for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFbE-UHvsb7-"
      },
      "outputs": [],
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALgrakUNpoH_"
      },
      "source": [
        "# Convert all of our data into torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw5K2A5Ko1RF"
      },
      "outputs": [],
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "outputs": [],
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNl8khAhPYju"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwQ7JcuJQZ0o"
      },
      "source": [
        "Now that our input data is properly formatted, it's time to fine tune the BERT model. \n",
        "\n",
        "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
        "\n",
        "We'll load [BertForSequenceClassification](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py#L1129). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n",
        "\n",
        "\n",
        "### The Fine-Tuning Process\n",
        "\n",
        "Because the pre-trained BERT layers already encode a lot of information about the language, training the classifier is relatively inexpensive. Rather than training every layer in a large model from scratch, it's as if we have already trained the bottom layers 95% of where they need to be, and only really need to train the top layer, with a bit of tweaking going on in the lower levels to accomodate our task.\n",
        "\n",
        "Sometimes practicioners will opt to \"freeze\" certain layers when fine-tuning, or to apply different learning rates, apply diminishing learning rates, etc. all in an effort to preserve the good quality weights in the network and speed up training (often considerably). In fact, recent research on BERT specifically has demonstrated that freezing the majority of the weights results in only minimal accuracy declines, but there are exceptions and broader rules of transfer learning that should also be considered. For example, if your task and fine-tuning dataset is very different from the dataset used to train the transfer learning model, freezing the weights may not be a good idea. We'll cover the broader scope of transfer learning in NLP in a future post.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnQW9E-bBCRt"
      },
      "source": [
        "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFsCTp_mporB",
        "outputId": "efe41b07-9c81-427f-cf96-c1c6ce021362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407873900/407873900 [00:11<00:00, 36969789.34B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuning,recommended the following hyperparameter ranges:\n",
        "- Batch size: 16, 32\n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "- Number of epochs: 2, 3, 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxSMw0FrptiL"
      },
      "outputs": [],
      "source": [
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLs72DuMODJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb9059b8-3b2d-444c-e01a-48b12975ed9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ],
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=2e-5,\n",
        "                     warmup=.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXZhFb4LnV5"
      },
      "source": [
        "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. At each pass we need to:\n",
        "\n",
        "Training loop:\n",
        "- Tell the model to compute gradients by setting the model in train mode\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Clear out the gradients calculated in the previous pass. In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "Evalution loop:\n",
        "- Tell the model not to compute gradients by setting th emodel in evaluation mode\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBzobghA22uD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c41a9c-a6c7-4a56-dec3-c84fdccad23f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.4635413634989943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  33%|███▎      | 1/3 [00:22<00:44, 22.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9296875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.95        88\n",
            "           1       0.58      0.64      0.61        11\n",
            "\n",
            "    accuracy                           0.91        99\n",
            "   macro avg       0.77      0.79      0.78        99\n",
            "weighted avg       0.91      0.91      0.91        99\n",
            "\n",
            "Train loss: 0.1639535226193922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|██████▋   | 2/3 [00:44<00:22, 22.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9921875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99        88\n",
            "           1       1.00      0.91      0.95        11\n",
            "\n",
            "    accuracy                           0.99        99\n",
            "   macro avg       0.99      0.95      0.97        99\n",
            "weighted avg       0.99      0.99      0.99        99\n",
            "\n",
            "Train loss: 0.1150957651635898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 3/3 [01:05<00:00, 21.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9921875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99        88\n",
            "           1       1.00      0.91      0.95        11\n",
            "\n",
            "    accuracy                           0.99        99\n",
            "   macro avg       0.99      0.95      0.97        99\n",
            "weighted avg       0.99      0.99      0.99        99\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "  predictions , true_labels = [], []\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()    \n",
        "    flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "  \n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "  print(classification_report(flat_true_labels, flat_predictions)) #print classification report after every report \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyRa-5CcHv_g"
      },
      "source": [
        "## Training Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "Let's take a look at our training loss over all batches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "beb5db88-2763-43e2-d610-d933426a3a64"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB7_uU-6poII"
      },
      "source": [
        "# Prediction on test data (unseen and unlabeled data )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKhHhoz4w_Y8"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv(\"/content/taskB.En.input.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3BILwAkx1GQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "ad60ec8d-dbfb-4638-c304-a40f80bd4039"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c00a64bd-1ecc-4573-b984-660635626ded\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saw a video of someone getting a hug. would LO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"This Christmas I hope you all either get vacc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's the alamo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I constantly have loads of the new symptoms bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>Tempting to renew my membership and vote again...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>This week has felt like the longest in history...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Of course it’s raining when I’m due to go out ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>Weigh up a lie before you tell it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>Upand dressed at a reasonable time once again ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c00a64bd-1ecc-4573-b984-660635626ded')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c00a64bd-1ecc-4573-b984-660635626ded button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c00a64bd-1ecc-4573-b984-660635626ded');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text\n",
              "0     saw a video of someone getting a hug. would LO...\n",
              "1     \"This Christmas I hope you all either get vacc...\n",
              "2                                        It's the alamo\n",
              "3     Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...\n",
              "4     I constantly have loads of the new symptoms bu...\n",
              "...                                                 ...\n",
              "1395  Tempting to renew my membership and vote again...\n",
              "1396  This week has felt like the longest in history...\n",
              "1397  Of course it’s raining when I’m due to go out ...\n",
              "1398                 Weigh up a lie before you tell it.\n",
              "1399  Upand dressed at a reasonable time once again ...\n",
              "\n",
              "[1400 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-10XM0r8xqUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c237edf-5f7d-4ea5-a18a-c8b58e7db952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "ps = PorterStemmer()\n",
        "\n",
        "\n",
        "b = list(test_data[\"text\"])\n",
        "\n",
        "\n",
        "wordnet=WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "import nltk.corpus\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "import string\n",
        "exclude = set(string.punctuation)\n",
        "corpus = []\n",
        "for i in range(len(b)):\n",
        "    review =re.sub(r'http\\S+', ' ', str(b[i]))\n",
        "    review = re.sub(\"\\d*\\.\\d+\",\"\",review)\n",
        "    review =re.sub(r'@\\S+', ' ', review)\n",
        "    \n",
        "    \n",
        "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
        "    \n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = ' '.join(review)\n",
        "\n",
        "    \n",
        "\n",
        "    corpus.append(review)\n",
        "test_data = test_data.assign(clean_text = corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQvSSG0SpoIJ"
      },
      "source": [
        "let's assume that label of all tweets is zero \n",
        "it does not effect on prediction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swYraRFDyRO0"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.assign(random_label=[0 for i in range(len(test_data[\"clean_text\"]))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbDvHbcfyhfq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "892151a5-5a9f-4f50-cc87-99001f190605"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e382bea6-dd42-45e6-a84c-af01edbd8266\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>random_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saw a video of someone getting a hug. would LO...</td>\n",
              "      <td>saw a video of someone getting a hug. would lo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"This Christmas I hope you all either get vacc...</td>\n",
              "      <td>\"this christmas i hope you all either get vacc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's the alamo</td>\n",
              "      <td>it's the alamo</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...</td>\n",
              "      <td>wind 5 mph e. barometer hpa, pressure trend. t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I constantly have loads of the new symptoms bu...</td>\n",
              "      <td>i constantly have loads of the new symptoms bu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>Tempting to renew my membership and vote again...</td>\n",
              "      <td>tempting to renew my membership and vote again...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>This week has felt like the longest in history...</td>\n",
              "      <td>this week has felt like the longest in history...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Of course it’s raining when I’m due to go out ...</td>\n",
              "      <td>of course it’s raining when i’m due to go out ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>Weigh up a lie before you tell it.</td>\n",
              "      <td>weigh up a lie before you tell it.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>Upand dressed at a reasonable time once again ...</td>\n",
              "      <td>upand dressed at a reasonable time once again ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e382bea6-dd42-45e6-a84c-af01edbd8266')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e382bea6-dd42-45e6-a84c-af01edbd8266 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e382bea6-dd42-45e6-a84c-af01edbd8266');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text  ... random_label\n",
              "0     saw a video of someone getting a hug. would LO...  ...            0\n",
              "1     \"This Christmas I hope you all either get vacc...  ...            0\n",
              "2                                        It's the alamo  ...            0\n",
              "3     Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...  ...            0\n",
              "4     I constantly have loads of the new symptoms bu...  ...            0\n",
              "...                                                 ...  ...          ...\n",
              "1395  Tempting to renew my membership and vote again...  ...            0\n",
              "1396  This week has felt like the longest in history...  ...            0\n",
              "1397  Of course it’s raining when I’m due to go out ...  ...            0\n",
              "1398                 Weigh up a lie before you tell it.  ...            0\n",
              "1399  Upand dressed at a reasonable time once again ...  ...            0\n",
              "\n",
              "[1400 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAg6Z5LmyKDL"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = test_data.clean_text.values\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = test_data.random_label.values\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "\n",
        "MAX_LEN = 128\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "  \n",
        "batch_size = 32  \n",
        "\n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6plBf36x-kW"
      },
      "outputs": [],
      "source": [
        "# Prediction on test set\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIxxG7ciyrar"
      },
      "outputs": [],
      "source": [
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxYGa6Bfy7Kn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b618de-a912-409c-ddea-0af09b8d8cc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "flat_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89OleVEzy93Z"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.assign(predicted_label=list(flat_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5-bBkLlzS2k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "e105bfe2-f222-422c-bdad-e507a6a98f12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8a0ea415-1bc5-49a6-b9bd-c55b02c5accb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>random_label</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saw a video of someone getting a hug. would LO...</td>\n",
              "      <td>saw a video of someone getting a hug. would lo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"This Christmas I hope you all either get vacc...</td>\n",
              "      <td>\"this christmas i hope you all either get vacc...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's the alamo</td>\n",
              "      <td>it's the alamo</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...</td>\n",
              "      <td>wind 5 mph e. barometer hpa, pressure trend. t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I constantly have loads of the new symptoms bu...</td>\n",
              "      <td>i constantly have loads of the new symptoms bu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>Tempting to renew my membership and vote again...</td>\n",
              "      <td>tempting to renew my membership and vote again...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>This week has felt like the longest in history...</td>\n",
              "      <td>this week has felt like the longest in history...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Of course it’s raining when I’m due to go out ...</td>\n",
              "      <td>of course it’s raining when i’m due to go out ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>Weigh up a lie before you tell it.</td>\n",
              "      <td>weigh up a lie before you tell it.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>Upand dressed at a reasonable time once again ...</td>\n",
              "      <td>upand dressed at a reasonable time once again ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a0ea415-1bc5-49a6-b9bd-c55b02c5accb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a0ea415-1bc5-49a6-b9bd-c55b02c5accb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a0ea415-1bc5-49a6-b9bd-c55b02c5accb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text  ... predicted_label\n",
              "0     saw a video of someone getting a hug. would LO...  ...               0\n",
              "1     \"This Christmas I hope you all either get vacc...  ...               0\n",
              "2                                        It's the alamo  ...               0\n",
              "3     Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...  ...               0\n",
              "4     I constantly have loads of the new symptoms bu...  ...               0\n",
              "...                                                 ...  ...             ...\n",
              "1395  Tempting to renew my membership and vote again...  ...               0\n",
              "1396  This week has felt like the longest in history...  ...               0\n",
              "1397  Of course it’s raining when I’m due to go out ...  ...               0\n",
              "1398                 Weigh up a lie before you tell it.  ...               0\n",
              "1399  Upand dressed at a reasonable time once again ...  ...               0\n",
              "\n",
              "[1400 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd8-Bj2TzXYS"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.drop([\"text\",\"clean_text\",\"random_label\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ggjw4cdszpYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc3839f-464b-496a-fe3e-cc226ddecf75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1395\n",
              "1       5\n",
              "Name: predicted_label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "test_data[\"predicted_label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MKC96QT0gD6"
      },
      "outputs": [],
      "source": [
        "test_data.to_csv(\"understatement_test_pred.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f3cCQmnFMknt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "BERT_Fine_Tuning_Sentence_Classification_overstatement (2).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}