{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNKaJz5j_ylj"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "## Install and Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEfSbAA4QHas",
        "outputId": "8c220d8d-efd1-4cb3-d54a-fb3f269f6ec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NmMdkZO8R6q",
        "outputId": "2a13280c-3552-472b-b5ec-c510b8278298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.8)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.62.3)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.10.0.2)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.8 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.24.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.8->boto3->pytorch-pretrained-bert) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.8->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.8->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ok002ceNB8E7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oYsV4H8fCpZ-",
        "outputId": "1ebd04c4-4554-41d3-eb11-9050fbc21dd9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fNetEz1xLsuh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "oR7zXtM2j_XV"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv(\"/content/satire_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it8ztkYCpoHs"
      },
      "source": [
        "this dataset consist of semeval training and test data + sem22 training data with data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xfOe7C19kgTJ",
        "outputId": "337d6460-b465-4cd2-f6c4-30e1012cadc2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fb78eb2e-8a81-4273-85ec-815cb4bd5162\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>satire</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>beautician and deadly the savage beast ( 1997 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>beautician romance and the phantom beast ( 199...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>beautician venus and the angry beast ( cannes ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>though taxes paid are just the best and someti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>taxes are often just above the three best and ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>70</td>\n",
              "      <td>@ mcfcok82 • thank to you for recognizing your...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>71</td>\n",
              "      <td>@ facebook mcfcok82 please thank you for your ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>72</td>\n",
              "      <td>@ detroitpistons @ atlanta pistonsgt cade cunn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>73</td>\n",
              "      <td>@ detroitpistons @ pistonsgt cade cunningham i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>74</td>\n",
              "      <td>@ lansing detroitpistons @ rochester pistonsgt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb78eb2e-8a81-4273-85ec-815cb4bd5162')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fb78eb2e-8a81-4273-85ec-815cb4bd5162 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fb78eb2e-8a81-4273-85ec-815cb4bd5162');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Unnamed: 0                                              tweet  satire\n",
              "0            0  beautician and deadly the savage beast ( 1997 ...       1\n",
              "1            1  beautician romance and the phantom beast ( 199...       1\n",
              "2            2  beautician venus and the angry beast ( cannes ...       1\n",
              "3            3  though taxes paid are just the best and someti...       1\n",
              "4            4  taxes are often just above the three best and ...       1\n",
              "..         ...                                                ...     ...\n",
              "70          70  @ mcfcok82 • thank to you for recognizing your...       1\n",
              "71          71  @ facebook mcfcok82 please thank you for your ...       1\n",
              "72          72  @ detroitpistons @ atlanta pistonsgt cade cunn...       1\n",
              "73          73  @ detroitpistons @ pistonsgt cade cunningham i...       1\n",
              "74          74  @ lansing detroitpistons @ rochester pistonsgt...       1\n",
              "\n",
              "[75 rows x 3 columns]"
            ]
          },
          "execution_count": 207,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "WVLFfTfAL5gz"
      },
      "outputs": [],
      "source": [
        "df2=df2.drop([\"Unnamed: 0\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "id": "hAdVCC5Ykk4d"
      },
      "outputs": [],
      "source": [
        "df2 = df2[[\"tweet\",\"satire\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "VNJnV3dVLFzp"
      },
      "outputs": [],
      "source": [
        "df30 = pd.read_csv(\"train.En (1).csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "8t721KVSK_ld"
      },
      "outputs": [],
      "source": [
        "df30_satire= df30[[\"tweet\",\"satire\"]]\n",
        "df30_satire = df30_satire[0:867]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aIMfWncELXXF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "kDox4JLMLTAl"
      },
      "outputs": [],
      "source": [
        "df30_satire=df2.append(df30_satire)\n",
        "df30_satire =df30_satire.drop_duplicates(subset=['tweet'])\n",
        "df30_satire = df30_satire.astype({\"satire\":int})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lPDeSgfTLoA7",
        "outputId": "e0e4c2bb-135c-4960-e932-dac959b2bfa7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dc1a0de5-0e43-4c83-ad90-6d1f20083cb9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>satire</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beautician and deadly the savage beast ( 1997 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>beautician romance and the phantom beast ( 199...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>beautician venus and the angry beast ( cannes ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>though taxes paid are just the best and someti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>taxes are often just above the three best and ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>yo @claires do yall do hysterectomies?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863</th>\n",
              "      <td>@JacobWohlReport Do I need to aquire a wife be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>I get a lot of boy who cried wolf vibes from t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>Update: holding hands with your mom and walkin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>I might be rubbish at driving, and have a less...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>942 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc1a0de5-0e43-4c83-ad90-6d1f20083cb9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc1a0de5-0e43-4c83-ad90-6d1f20083cb9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc1a0de5-0e43-4c83-ad90-6d1f20083cb9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 tweet  satire\n",
              "0    beautician and deadly the savage beast ( 1997 ...       1\n",
              "1    beautician romance and the phantom beast ( 199...       1\n",
              "2    beautician venus and the angry beast ( cannes ...       1\n",
              "3    though taxes paid are just the best and someti...       1\n",
              "4    taxes are often just above the three best and ...       1\n",
              "..                                                 ...     ...\n",
              "862             yo @claires do yall do hysterectomies?       0\n",
              "863  @JacobWohlReport Do I need to aquire a wife be...       0\n",
              "864  I get a lot of boy who cried wolf vibes from t...       0\n",
              "865  Update: holding hands with your mom and walkin...       0\n",
              "866  I might be rubbish at driving, and have a less...       0\n",
              "\n",
              "[942 rows x 2 columns]"
            ]
          },
          "execution_count": 213,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df30_satire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "YJWmwsTDMeSO"
      },
      "outputs": [],
      "source": [
        "df = df30_satire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "AQfTaYDo42zu",
        "outputId": "8b09eea5-f6d9-4e42-e724-226ddbe48521"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-49abe2f2-5891-4a14-b308-40266924d897\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>satire</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>@BoardroomBoy Few links for you. To summarise,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>678</th>\n",
              "      <td>I’m in Canada so like Happy 4rth?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551</th>\n",
              "      <td>@SkySportsBoxing if i think you would have a c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>yeah say i ’ will m following a pretty lot of ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>I love to pick my modules on a first come firs...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>love living in a capitalist society where i lo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>@ThomasCabaret84 @MicrobiomDigest @raoult_didi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>STOP TREATING MARS LIKE A BACK-UP BOYFRIEND JU...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>who needs an alarm when u can have the low rum...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>Just got in, how’d Liverpool get on?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49abe2f2-5891-4a14-b308-40266924d897')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49abe2f2-5891-4a14-b308-40266924d897 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49abe2f2-5891-4a14-b308-40266924d897');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 tweet  satire\n",
              "138  @BoardroomBoy Few links for you. To summarise,...       0\n",
              "678                  I’m in Canada so like Happy 4rth?       0\n",
              "551  @SkySportsBoxing if i think you would have a c...       1\n",
              "66   yeah say i ’ will m following a pretty lot of ...       1\n",
              "733  I love to pick my modules on a first come firs...       0\n",
              "81   love living in a capitalist society where i lo...       0\n",
              "270  @ThomasCabaret84 @MicrobiomDigest @raoult_didi...       0\n",
              "113  STOP TREATING MARS LIKE A BACK-UP BOYFRIEND JU...       0\n",
              "433  who needs an alarm when u can have the low rum...       0\n",
              "567               Just got in, how’d Liverpool get on?       0"
            ]
          },
          "execution_count": 215,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3DjEe9eeCm_",
        "outputId": "2bb2d600-72f8-4359-aa6c-1be1ce4a34cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    842\n",
              "1    100\n",
              "Name: satire, dtype: int64"
            ]
          },
          "execution_count": 216,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"satire\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "7qZkevCJRT0D"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"satire_all_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJMHkIvWpoH5"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clkFG-g1LS_e",
        "outputId": "f1a119e8-9aab-4a6f-c5fc-14965cd2d375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import nltk.corpus\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "\n",
        "b = list(df[\"tweet\"])\n",
        "corpus = []\n",
        "for i in range(len(b)):\n",
        "    review =re.sub(r'http\\S+', ' ', str(b[i]))\n",
        "    review = re.sub(\"\\d*\\.\\d+\",\"\",review) # remove float \n",
        "    review =re.sub(r'@\\S+', ' ', review)\n",
        "    \n",
        "    TAG_RE = re.compile(r'<[^>]+>')\n",
        "    review = TAG_RE.sub('', review)\n",
        "\n",
        "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
        "    \n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = ' '.join(review)\n",
        "\n",
        "    \n",
        "\n",
        "    corpus.append(review)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "APY0U2xiMLuS"
      },
      "outputs": [],
      "source": [
        "df = df.assign(clean_headlines = corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "DlY6XbOQMqTT",
        "outputId": "448ab679-6364-4c95-a40e-3f63cccd8d74"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ef418bdc-08c1-4072-b886-3186cd80ce47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>satire</th>\n",
              "      <th>clean_headlines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beautician and deadly the savage beast ( 1997 ...</td>\n",
              "      <td>1</td>\n",
              "      <td>beautician and deadly the savage beast ( 1997 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>beautician romance and the phantom beast ( 199...</td>\n",
              "      <td>1</td>\n",
              "      <td>beautician romance and the phantom beast ( 199...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>beautician venus and the angry beast ( cannes ...</td>\n",
              "      <td>1</td>\n",
              "      <td>beautician venus and the angry beast ( cannes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>though taxes paid are just the best and someti...</td>\n",
              "      <td>1</td>\n",
              "      <td>though taxes paid are just the best and someti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>taxes are often just above the three best and ...</td>\n",
              "      <td>1</td>\n",
              "      <td>taxes are often just above the three best and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>yo @claires do yall do hysterectomies?</td>\n",
              "      <td>0</td>\n",
              "      <td>yo do yall do hysterectomies?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863</th>\n",
              "      <td>@JacobWohlReport Do I need to aquire a wife be...</td>\n",
              "      <td>0</td>\n",
              "      <td>do i need to aquire a wife before this happens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>I get a lot of boy who cried wolf vibes from t...</td>\n",
              "      <td>0</td>\n",
              "      <td>i get a lot of boy who cried wolf vibes from t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>Update: holding hands with your mom and walkin...</td>\n",
              "      <td>0</td>\n",
              "      <td>update: holding hands with your mom and walkin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>I might be rubbish at driving, and have a less...</td>\n",
              "      <td>0</td>\n",
              "      <td>i might be rubbish at driving, and have a less...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>942 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef418bdc-08c1-4072-b886-3186cd80ce47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef418bdc-08c1-4072-b886-3186cd80ce47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef418bdc-08c1-4072-b886-3186cd80ce47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 tweet  ...                                    clean_headlines\n",
              "0    beautician and deadly the savage beast ( 1997 ...  ...  beautician and deadly the savage beast ( 1997 ...\n",
              "1    beautician romance and the phantom beast ( 199...  ...  beautician romance and the phantom beast ( 199...\n",
              "2    beautician venus and the angry beast ( cannes ...  ...  beautician venus and the angry beast ( cannes ...\n",
              "3    though taxes paid are just the best and someti...  ...  though taxes paid are just the best and someti...\n",
              "4    taxes are often just above the three best and ...  ...  taxes are often just above the three best and ...\n",
              "..                                                 ...  ...                                                ...\n",
              "862             yo @claires do yall do hysterectomies?  ...                      yo do yall do hysterectomies?\n",
              "863  @JacobWohlReport Do I need to aquire a wife be...  ...  do i need to aquire a wife before this happens...\n",
              "864  I get a lot of boy who cried wolf vibes from t...  ...  i get a lot of boy who cried wolf vibes from t...\n",
              "865  Update: holding hands with your mom and walkin...  ...  update: holding hands with your mom and walkin...\n",
              "866  I might be rubbish at driving, and have a less...  ...  i might be rubbish at driving, and have a less...\n",
              "\n",
              "[942 rows x 3 columns]"
            ]
          },
          "execution_count": 220,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XodhrvVDpoH6"
      },
      "source": [
        "# Add special tokens at the beginning and end of each sentence for BERT to work properly "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "outputs": [],
      "source": [
        "# Create sentence and label lists\n",
        "sentences = df.clean_headlines.values\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = df.satire.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "## Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTREubVNFiz4"
      },
      "source": [
        "Next, import the BERT tokenizer, used to convert our text into tokens that correspond to BERT's vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PniouibtahT",
        "outputId": "eaf43465-290b-4040-d947-e6cf9a70c1e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.21.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (0.0.47)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.62.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (0.1.96)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.8 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (1.24.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (0.5.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.8->boto3->pytorch-transformers) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.8->boto3->pytorch-transformers) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.8->boto3->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-transformers\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "ODCKPuvMtVwF"
      },
      "outputs": [],
      "source": [
        "from pytorch_transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
        "from pytorch_transformers import AdamW\n",
        "\n",
        "from tqdm import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z474sSC6oe7A",
        "outputId": "f46c3ec2-7005-4c08-f08c-b325792866f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenize the first sentence:\n",
            "['[CLS]', 'beau', '##tic', '##ian', 'and', 'deadly', 'the', 'savage', 'beast', '(', '1997', ')', '.', '25th', 'best', 'of', 'timothy', 'ross', 'dalton', 'film', 'of', 'all', 'year', 'time', '.', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print (\"Tokenize the first sentence:\")\n",
        "print (tokenized_texts[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87_kXUeT2-br"
      },
      "source": [
        "BERT requires specifically formatted inputs. For each tokenized input sentence, we need to create:\n",
        "\n",
        "- **input ids**: a sequence of integers identifying each input token to its index number in the BERT tokenizer vocabulary\n",
        "- **segment mask**: (optional) a sequence of 1s and 0s used to identify whether the input is one sentence or two sentences long. For one sentence inputs, this is simply a sequence of 0s. For two sentence inputs, there is a 0 for each token of the first sentence, followed by a 1 for each token of the second sentence\n",
        "- **attention mask**: (optional) a sequence of 1s and 0s, with 1s for all input tokens and 0s for all padding tokens (we'll detail this in the next paragraph)\n",
        "- **labels**: a single value of 1 or 0. In our task 1 means \"grammatical\" and 0 means \"ungrammatical\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xytsw1oIfnX0"
      },
      "source": [
        "Although we can have variable length input sentences, BERT does requires our input arrays to be the same size. We address this by first choosing a maximum sentence length, and then padding and truncating our inputs until every input sequence is of the same length. \n",
        "\n",
        "To \"pad\" our inputs in this context means that if a sentence is shorter than the maximum sentence length, we simply add 0s to the end of the sequence until it is the maximum sentence length. \n",
        "\n",
        "If a sentence is longer than the maximum sentence length, then we simply truncate the end of the sequence, discarding anything that does not fit into our maximum sentence length.\n",
        "\n",
        "We pad and truncate our sequences so that they all become of length MAX_LEN (\"post\" indicates that we want to pad and truncate at the end of the sequence, as opposed to the beginning) `pad_sequences` is a utility function that we're borrowing from Keras. It simply handles the truncating and padding of Python lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "Cp9BPRd1tMIo"
      },
      "outputs": [],
      "source": [
        "# Set the maximum sequence length \n",
        "MAX_LEN = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "id": "uZeXeNXgo0iQ"
      },
      "outputs": [],
      "source": [
        "# Pad our input tokens\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "id": "mFhowDMohU4H"
      },
      "outputs": [],
      "source": [
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "id": "kDs-MYtYH8sL"
      },
      "outputs": [],
      "source": [
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhGulL1pExCT"
      },
      "source": [
        "# Create the attention masks "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "cDoC24LeEv3N"
      },
      "outputs": [],
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3pmYGGRpoH-"
      },
      "source": [
        "# Split our data into train and validation sets for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "aFbE-UHvsb7-"
      },
      "outputs": [],
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALgrakUNpoH_"
      },
      "source": [
        "# Convert all of our data into torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "jw5K2A5Ko1RF"
      },
      "outputs": [],
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "outputs": [],
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNl8khAhPYju"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwQ7JcuJQZ0o"
      },
      "source": [
        "Now that our input data is properly formatted, it's time to fine tune the BERT model. \n",
        "\n",
        "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
        "\n",
        "We'll load [BertForSequenceClassification](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py#L1129). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n",
        "\n",
        "\n",
        "### The Fine-Tuning Process\n",
        "\n",
        "Because the pre-trained BERT layers already encode a lot of information about the language, training the classifier is relatively inexpensive. Rather than training every layer in a large model from scratch, it's as if we have already trained the bottom layers 95% of where they need to be, and only really need to train the top layer, with a bit of tweaking going on in the lower levels to accomodate our task.\n",
        "\n",
        "Sometimes practicioners will opt to \"freeze\" certain layers when fine-tuning, or to apply different learning rates, apply diminishing learning rates, etc. all in an effort to preserve the good quality weights in the network and speed up training (often considerably). In fact, recent research on BERT specifically has demonstrated that freezing the majority of the weights results in only minimal accuracy declines, but there are exceptions and broader rules of transfer learning that should also be considered. For example, if your task and fine-tuning dataset is very different from the dataset used to train the transfer learning model, freezing the weights may not be a good idea. We'll cover the broader scope of transfer learning in NLP in a future post.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnQW9E-bBCRt"
      },
      "source": [
        "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFsCTp_mporB",
        "outputId": "19d1c30e-7c8a-4442-8665-1ae6e58728f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 232,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuning,recommended the following hyperparameter ranges:\n",
        "- Batch size: 16, 32\n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "- Number of epochs: 2, 3, 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "QxSMw0FrptiL"
      },
      "outputs": [],
      "source": [
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLs72DuMODJO",
        "outputId": "020845f0-51e4-4ca8-deb3-1de34a9422b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ],
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=2e-5,\n",
        "                     warmup=.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXZhFb4LnV5"
      },
      "source": [
        "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. At each pass we need to:\n",
        "\n",
        "Training loop:\n",
        "- Tell the model to compute gradients by setting the model in train mode\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Clear out the gradients calculated in the previous pass. In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "Evalution loop:\n",
        "- Tell the model not to compute gradients by setting th emodel in evaluation mode\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "nBzobghA22uD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J-FYdx6nFE_",
        "outputId": "a27dc61d-6354-45ab-efdb-1009f58bd8c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.2930846571991289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  33%|███▎      | 1/3 [00:42<01:25, 42.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9895833333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99        89\n",
            "           1       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.99        95\n",
            "   macro avg       0.99      0.92      0.95        95\n",
            "weighted avg       0.99      0.99      0.99        95\n",
            "\n",
            "Train loss: 0.0404181279828427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  67%|██████▋   | 2/3 [01:25<00:42, 42.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9895833333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99        89\n",
            "           1       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.99        95\n",
            "   macro avg       0.99      0.92      0.95        95\n",
            "weighted avg       0.99      0.99      0.99        95\n",
            "\n",
            "Train loss: 0.009934759957508909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 3/3 [02:07<00:00, 42.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9895833333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99        89\n",
            "           1       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.99        95\n",
            "   macro avg       0.99      0.92      0.95        95\n",
            "weighted avg       0.99      0.99      0.99        95\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "  predictions , true_labels = [], []\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()    \n",
        "    flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "  \n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "  print(classification_report(flat_true_labels, flat_predictions)) #print classification report after every report \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyRa-5CcHv_g"
      },
      "source": [
        "## Training Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "Let's take a look at our training loss over all batches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "68xreA9JAmG5",
        "outputId": "237debe1-04c1-4d17-ce21-1e848e21ee54"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB7_uU-6poII"
      },
      "source": [
        "# Prediction on test data (unseen and unlabeled data )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "CKhHhoz4w_Y8"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv(\"/content/taskB.En.input.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "e3BILwAkx1GQ",
        "outputId": "a118558c-e4ac-4233-d1ea-9b82e2edd33c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9339d4de-e19e-4090-a769-89468f0c7c4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saw a video of someone getting a hug. would LO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"This Christmas I hope you all either get vacc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's the alamo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I constantly have loads of the new symptoms bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>Tempting to renew my membership and vote again...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>This week has felt like the longest in history...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Of course it’s raining when I’m due to go out ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>Weigh up a lie before you tell it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>Upand dressed at a reasonable time once again ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9339d4de-e19e-4090-a769-89468f0c7c4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9339d4de-e19e-4090-a769-89468f0c7c4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9339d4de-e19e-4090-a769-89468f0c7c4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text\n",
              "0     saw a video of someone getting a hug. would LO...\n",
              "1     \"This Christmas I hope you all either get vacc...\n",
              "2                                        It's the alamo\n",
              "3     Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...\n",
              "4     I constantly have loads of the new symptoms bu...\n",
              "...                                                 ...\n",
              "1395  Tempting to renew my membership and vote again...\n",
              "1396  This week has felt like the longest in history...\n",
              "1397  Of course it’s raining when I’m due to go out ...\n",
              "1398                 Weigh up a lie before you tell it.\n",
              "1399  Upand dressed at a reasonable time once again ...\n",
              "\n",
              "[1400 rows x 1 columns]"
            ]
          },
          "execution_count": 243,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-10XM0r8xqUf",
        "outputId": "71973523-8808-4688-ca77-5527cd73c70f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "ps = PorterStemmer()\n",
        "\n",
        "\n",
        "b = list(test_data[\"text\"])\n",
        "\n",
        "\n",
        "wordnet=WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "import nltk.corpus\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "import string\n",
        "exclude = set(string.punctuation)\n",
        "corpus = []\n",
        "for i in range(len(b)):\n",
        "    review =re.sub(r'http\\S+', ' ', str(b[i]))\n",
        "    review = re.sub(\"\\d*\\.\\d+\",\"\",review)\n",
        "    review =re.sub(r'@\\S+', ' ', review)\n",
        "    \n",
        "    \n",
        "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
        "    \n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = ' '.join(review)\n",
        "\n",
        "    \n",
        "\n",
        "    corpus.append(review)\n",
        "test_data = test_data.assign(clean_text = corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQvSSG0SpoIJ"
      },
      "source": [
        "let's assume that label of all tweets is zero \n",
        "it does not effect on prediction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "swYraRFDyRO0"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.assign(random_label=[0 for i in range(len(test_data[\"clean_text\"]))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jbDvHbcfyhfq",
        "outputId": "2b060560-7345-4017-ffbf-87277f07a98d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2ae2bc0b-c172-41ca-88a9-1f421c3eb577\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>random_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saw a video of someone getting a hug. would LO...</td>\n",
              "      <td>saw a video of someone getting a hug. would lo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"This Christmas I hope you all either get vacc...</td>\n",
              "      <td>\"this christmas i hope you all either get vacc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's the alamo</td>\n",
              "      <td>it's the alamo</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...</td>\n",
              "      <td>wind 5 mph e. barometer hpa, pressure trend. t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I constantly have loads of the new symptoms bu...</td>\n",
              "      <td>i constantly have loads of the new symptoms bu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>Tempting to renew my membership and vote again...</td>\n",
              "      <td>tempting to renew my membership and vote again...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>This week has felt like the longest in history...</td>\n",
              "      <td>this week has felt like the longest in history...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Of course it’s raining when I’m due to go out ...</td>\n",
              "      <td>of course it’s raining when i’m due to go out ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>Weigh up a lie before you tell it.</td>\n",
              "      <td>weigh up a lie before you tell it.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>Upand dressed at a reasonable time once again ...</td>\n",
              "      <td>upand dressed at a reasonable time once again ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ae2bc0b-c172-41ca-88a9-1f421c3eb577')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ae2bc0b-c172-41ca-88a9-1f421c3eb577 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ae2bc0b-c172-41ca-88a9-1f421c3eb577');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text  ... random_label\n",
              "0     saw a video of someone getting a hug. would LO...  ...            0\n",
              "1     \"This Christmas I hope you all either get vacc...  ...            0\n",
              "2                                        It's the alamo  ...            0\n",
              "3     Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...  ...            0\n",
              "4     I constantly have loads of the new symptoms bu...  ...            0\n",
              "...                                                 ...  ...          ...\n",
              "1395  Tempting to renew my membership and vote again...  ...            0\n",
              "1396  This week has felt like the longest in history...  ...            0\n",
              "1397  Of course it’s raining when I’m due to go out ...  ...            0\n",
              "1398                 Weigh up a lie before you tell it.  ...            0\n",
              "1399  Upand dressed at a reasonable time once again ...  ...            0\n",
              "\n",
              "[1400 rows x 3 columns]"
            ]
          },
          "execution_count": 246,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "tAg6Z5LmyKDL"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = test_data.clean_text.values\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = test_data.random_label.values\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "\n",
        "MAX_LEN = 128\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "  \n",
        "batch_size = 32  \n",
        "\n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "W6plBf36x-kW"
      },
      "outputs": [],
      "source": [
        "# Prediction on test set\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "wIxxG7ciyrar"
      },
      "outputs": [],
      "source": [
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxYGa6Bfy7Kn",
        "outputId": "834d8b72-25d4-4584-99cf-c798e1833502"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "execution_count": 250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flat_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "89OleVEzy93Z"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.assign(predicted_label=list(flat_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "p5-bBkLlzS2k",
        "outputId": "9c98ab76-b3c7-4a98-ae70-3414c7f8f72c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8798738d-ee39-483e-a5bc-f2f61f45e9ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>random_label</th>\n",
              "      <th>predicted_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saw a video of someone getting a hug. would LO...</td>\n",
              "      <td>saw a video of someone getting a hug. would lo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"This Christmas I hope you all either get vacc...</td>\n",
              "      <td>\"this christmas i hope you all either get vacc...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's the alamo</td>\n",
              "      <td>it's the alamo</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...</td>\n",
              "      <td>wind 5 mph e. barometer hpa, pressure trend. t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I constantly have loads of the new symptoms bu...</td>\n",
              "      <td>i constantly have loads of the new symptoms bu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>Tempting to renew my membership and vote again...</td>\n",
              "      <td>tempting to renew my membership and vote again...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>This week has felt like the longest in history...</td>\n",
              "      <td>this week has felt like the longest in history...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>Of course it’s raining when I’m due to go out ...</td>\n",
              "      <td>of course it’s raining when i’m due to go out ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>Weigh up a lie before you tell it.</td>\n",
              "      <td>weigh up a lie before you tell it.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>Upand dressed at a reasonable time once again ...</td>\n",
              "      <td>upand dressed at a reasonable time once again ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8798738d-ee39-483e-a5bc-f2f61f45e9ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8798738d-ee39-483e-a5bc-f2f61f45e9ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8798738d-ee39-483e-a5bc-f2f61f45e9ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text  ... predicted_label\n",
              "0     saw a video of someone getting a hug. would LO...  ...               0\n",
              "1     \"This Christmas I hope you all either get vacc...  ...               0\n",
              "2                                        It's the alamo  ...               0\n",
              "3     Wind 5 mph E. Barometer 1029.8 hPa, Pressure t...  ...               0\n",
              "4     I constantly have loads of the new symptoms bu...  ...               0\n",
              "...                                                 ...  ...             ...\n",
              "1395  Tempting to renew my membership and vote again...  ...               0\n",
              "1396  This week has felt like the longest in history...  ...               0\n",
              "1397  Of course it’s raining when I’m due to go out ...  ...               0\n",
              "1398                 Weigh up a lie before you tell it.  ...               0\n",
              "1399  Upand dressed at a reasonable time once again ...  ...               0\n",
              "\n",
              "[1400 rows x 4 columns]"
            ]
          },
          "execution_count": 252,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "wd8-Bj2TzXYS"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.drop([\"text\",\"clean_text\",\"random_label\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggjw4cdszpYy",
        "outputId": "356ac934-2067-4b83-a7e3-3b7ccb0122cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1395\n",
              "1       5\n",
              "Name: predicted_label, dtype: int64"
            ]
          },
          "execution_count": 254,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[\"predicted_label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "6MKC96QT0gD6"
      },
      "outputs": [],
      "source": [
        "test_data.to_csv(\"satire_test_pred.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "BERT_Fine_Tuning_Sentence_Classification_satire.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
